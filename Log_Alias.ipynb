{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Log-Alias.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM9h3/ra46lX1Pn/xYJUWHF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsaif/Log-Alias/blob/main/Log_Alias.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd4lAm6RAOZx"
      },
      "source": [
        "#**Log Alias**\r\n",
        "Usually we deal with broad range of well log mnemonics, this brief codes (and bunch of log aliases) tried to uniform the log alias into one specific name. It also merge similar log type but has different mnemonic and interval within the same well. Further development should need a normalization for each log before the merging begin because different mnemonics might be due to different service company or tools in which the measurement could be different. These codes could be applied for single well or multi well.\r\n",
        "\r\n",
        "**Input:**\r\n",
        "A csv file consist of log measurements (and well name if you want to run multiwell), each column consist of one log. I recommend using lasio to read LAS file and convert it to dataframe, later you can save it as csv to be inputted in these code, or, you can directly use the dataframe as input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHECKwaC-5D8"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "#Alias KataLog\r\n",
        "#Caliper\r\n",
        "CAL = ['C1', 'C1S', 'C2', 'CAL1R', 'CAL1R_R', 'CALD', 'CALI', 'CALI_1', 'CALI_2', 'CALI_SCPS', 'CALR', 'CALS', 'CALSR', 'CALSR_R', 'CALX', 'DCAL', 'HCAL', 'HCAL2R', 'HCALD', 'HCALR', 'HCALS', 'HCAL_1', 'HCAL_2', 'HCGRR', 'HD', 'HD1', 'HD2', 'HDS', 'HSGRR', 'LCAL', 'LCALD', 'LCALR', 'LCAL_1']\r\n",
        "\r\n",
        "#Lithology Log\r\n",
        "GR = ['CGR', 'CGRD', 'CGRR', 'CGRS', 'ECGR', 'ECGRD', 'ECGREDTC', 'ECGRR', 'ECGRS', 'GR', 'GRC', 'GRD', 'GRD1', 'GRD_1', 'GRN', 'GRR', 'GRR_R', 'GRR_R1', 'GRR_R2', 'GRS', 'GRS1', 'GRT', 'GR_1', 'GR_EDTC', 'GR_STGC', 'HCGR', 'HCGRD', 'HCGRS', 'HGRT', 'HSGR', 'HSGRD', 'HSGRS', 'MSGRR', 'SGR', 'SGRD', 'SGRDD', 'SGRR', 'SGRS']\r\n",
        "SP = ['SPR']\r\n",
        "PEF = ['PE', 'PEF', 'PEFL', 'PEFS', 'PEFZ', 'PEF_SLDT']\r\n",
        "GR_OTHER = ['HFK', 'HTHO', 'HURA', 'THOR', 'URAN', 'CGRRPOTA']\r\n",
        "\r\n",
        "#Porosity Log\r\n",
        "NPHI = ['CNC', 'CNC_LS', 'CNPOR_LS', 'ENPH_LS', 'NPHI', 'NPHI1', 'NPHILS_1', 'NPHILs', 'NPHI_LS', 'NPHI_LS_1', 'NPHS', 'NPOR', 'NPORLS', 'NPOR_LS', 'SNP', 'TNPH', 'TNPH_LIM', 'TNPH_LS', 'TNPH_SS', 'TNPJ_LS_1', 'TPHI_LS']\r\n",
        "DPHI =['DPHI', 'DPHI_LS', 'DPHI_LS', 'DPHI_SLDT', 'DPHZ', 'DPHZ2', 'DPHZ_LS', 'DPOR', 'DPOR_LS', 'DPO_LS', 'PORZ', 'PORZ_LS']\r\n",
        "DENS = ['DCOR', 'RHOM','DPHZLS', 'DPHZ_SS', 'DPO', 'RHOB', 'RHOB_SLDT', 'RHOZ', 'ZCOR', 'ZDEN']\r\n",
        "POR_OTHER = ['APLCLS', 'APLC_LS', 'NRHO', 'PHIND_LS', 'PHIX', 'PHND_LS', 'PORS_LS', 'PXND', 'SPHI', 'SPHILS', 'SPHI_LS', 'SPHI_SS','NEUT']\r\n",
        "POR = ['CNC', 'CNC_LS', 'CNPOR_LS', 'ENPH_LS', 'NPHI', 'NPHI1', 'NPHILS_1', 'NPHILs', 'NPHI_LS', 'NPHI_LS_1', 'NPHS', 'NPOR', 'NPORLS', 'NPOR_LS', 'SNP', 'TNPH', 'TNPH_LIM', 'TNPH_LS', 'TNPH_SS', 'TNPJ_LS_1', 'TPHI_LS','DPHI', 'DPHI_LS', 'DPHI_LS', 'DPHI_SLDT', 'DPHZ', 'DPHZ2', 'DPHZ_LS', 'DPOR', 'DPOR_LS', 'DPO_LS', 'PORZ', 'PORZ_LS','PHIND_LS', 'PHIX', 'PHND_LS', 'PORS_LS', 'PXND', 'SPHI', 'SPHILS', 'SPHI_LS', 'SPHI_SS']\r\n",
        "\r\n",
        "#Resistivity Log\r\n",
        "DRES = ['AE90', 'AF60', 'AF90', 'AHF60', 'AHFCO60', 'AHT60', 'AHT90', 'AO60', 'AO90', 'AST90', 'AT60', 'AT90', 'CILD', 'HLLD', 'HRID', 'IDPC', 'IDPH', 'ILD', 'ILD1', 'ILD_1', 'LLD', 'LLD_R', 'LLD_R1', 'LLD_R2', 'RILD', 'RLA4', 'RLA5', 'RT_HRLT', 'TBI60', 'TBIT90']\r\n",
        "MRES = ['AE30', 'AST30', 'AT30', 'HRIM', 'ILM', 'ILM_1', 'IMBC', 'IMPH', 'RLA4']\r\n",
        "SRES = ['AE10', 'AE20', 'AF10', 'AF20', 'AF30', 'AHF20', 'AHT10', 'AHT20', 'AHT30', 'AST10', 'AT10', 'AT20', 'HLLS', 'LLS', 'LLS_R', 'LLS_R1', 'LLS_R2', 'RLA3', 'TBIT20', 'TBIT30']\r\n",
        "RXO = ['HMIN', 'HMNO', 'MGUARD', 'MSFL', 'MSFL_R', 'RLA1', 'RLA2', 'RXO8', 'RXOZ', 'RXOZ_R', 'RXO_HRLT', 'SFL', 'SFLA', 'SFLU', 'SFLU_1', 'SFLU_1']\r\n",
        "CONDUCTIVITY = ['AFCO', 'AFCO60', 'CIDP']\r\n",
        "\r\n",
        "#DT\r\n",
        "DT = ['DTCO']#['DT', 'DT1', 'DT1R', 'DT1T', 'DT2', 'DT2R', 'DT4P', 'DT4PR', 'DT4PT', 'DTC', 'DTCM', 'DTCO', 'DTCO1', 'DTCO_1', 'DTL', 'DTLF', 'DTLN', 'DTOT', 'DTRP', 'DTTP', 'DTX', 'DTY', 'MODT', 'XDT2', 'YDT']\r\n",
        "DTS = ['DTSM']#['DT4S', 'DT4SR', 'DT4ST', 'DTM', 'DTRS', 'DTS', 'DTSM', 'DTSM_FAST','DTSM_SLOW', 'DTST', 'DTTS']\r\n",
        "DT_OTHER = ['DTM','DTSH']\r\n",
        "\r\n",
        "DRHO = ['CORR', 'DRH', 'DRHO', 'HDRA', 'QRHO', 'QRHO_SLDT']\r\n",
        "PR =['PR']\r\n",
        "VPVS =['PYR', 'VPVS', 'VPVS_X', 'VPVS_Y']\r\n",
        "\r\n",
        "#Drilling and others\r\n",
        "DRILL = ['CBL', 'CIRF_FIL', 'DEVI', 'GRATIO', 'GTEM', 'HD1_PPC1', 'HD2_PPC1', 'HD2_PPC2', 'LTEN', 'RB', 'ROP', 'SIGMA', 'STIT', 'TEN', 'TEND', 'TEND1', 'TEND_1', 'TENR', 'TENR', 'TENR_R', 'TENR_R1', 'TENR_R2', 'TENS', 'TENS1', 'TENT', 'WTEP']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHh_27x-_dia"
      },
      "source": [
        "source_dir = '/source/'\r\n",
        "db = pd.read_csv('Data_Raw.csv')\r\n",
        "output_file = ('merged.csv')\r\n",
        "\r\n",
        "loglist = {'CAL':CAL,'GR':GR,'SP':SP,'NPHI':NPHI,'DRES':DRES,'PEF':PEF,'RHOB':DENS,'DRHO':DRHO,'DTCO':DT}\r\n",
        "well = db['WELL'].unique()\r\n",
        "merged_data = pd.DataFrame()\r\n",
        "for i in range(len(well)):\r\n",
        "    data = db.where(db['WELL']==well[i]).dropna(axis=1, how='all')\r\n",
        "    for j in range(len(loglist)):\r\n",
        "        welllog_name = list(set(data.columns).intersection(loglist.get(list(loglist)[j])))\r\n",
        "        samelog = data[welllog_name]\r\n",
        "        count_log = dict(sorted(zip(welllog_name, samelog.count()), key=lambda item: item[1], reverse=True))\r\n",
        "        welllog_name = list(count_log.keys())\r\n",
        "        if (len(welllog_name)!=0):\r\n",
        "            for k in range(len(welllog_name)-1):\r\n",
        "              data[welllog_name[0]].fillna(data[welllog_name[k+1]], inplace=True)\r\n",
        "            print (welllog_name[0])\r\n",
        "            data[list(loglist)[j]] = data[welllog_name[0]]\r\n",
        "    merged_data = merged_data.append(data)\r\n",
        "    merged_data = merged_data[merged_data['WELL'].notna()]\r\n",
        "    \r\n",
        "merged_data.to_csv(f\"{source_dir}/{file_name}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}